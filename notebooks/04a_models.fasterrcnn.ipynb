{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp models.fasterrcnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FasterRCNN\n",
    "\n",
    "> API - details..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from nbdev.showdoc import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models.detection.backbone_utils import resnet_fpn_backbone\n",
    "from torchvision.models.utils import load_state_dict_from_url\n",
    "from torchvision.models.detection.anchor_utils import AnchorGenerator\n",
    "from torchvision.ops.feature_pyramid_network import FeaturePyramidNetwork\n",
    "from torchvision.models.detection import FasterRCNN\n",
    "from torchvision.ops.misc import FrozenBatchNorm2d\n",
    "from functools import partial\n",
    "from fastai.vision.all import default_device, delegates\n",
    "from fastai_object_detection.external.swin_transformer_source import SwinTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "#hide\n",
    "_model_urls = {\n",
    "    'fasterrcnn_resnet50_fpn_coco':\n",
    "        'https://download.pytorch.org/models/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth',\n",
    "    'fasterrcnn_mobilenet_v3_large_320_fpn_coco':\n",
    "        'https://download.pytorch.org/models/fasterrcnn_mobilenet_v3_large_320_fpn-907ea3f9.pth',\n",
    "    'fasterrcnn_mobilenet_v3_large_fpn_coco':\n",
    "        'https://download.pytorch.org/models/fasterrcnn_mobilenet_v3_large_fpn-fb6a3cc7.pth',\n",
    "    'swin_tiny_224': 'https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_tiny_patch4_window7_224.pth',\n",
    "    'swin_small_224': 'https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_small_patch4_window7_224.pth',\n",
    "    'swin_base_224': 'https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_base_patch4_window7_224.pth',\n",
    "    'swin_base_384': 'https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_base_patch4_window12_384.pth',\n",
    "    'swin_large_224': 'https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_large_patch4_window7_224_22kto1k.pth',\n",
    "    'swin_large_384': 'https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_large_patch4_window12_384_22kto1k.pth'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@delegates(FasterRCNN)\n",
    "def get_fasterrcnn_model(arch_str, num_classes, pretrained=True, pretrained_backbone=True, \n",
    "                   trainable_layers=5, **kwargs):\n",
    "    \"\"\"Creates FasterRCNN model with resnet backbone\"\"\"\n",
    "    \n",
    "    #if pretrained == True: pretrained_backbone=False\n",
    "        \n",
    "    backbone = resnet_fpn_backbone(arch_str, pretrained=pretrained_backbone, trainable_layers=trainable_layers)\n",
    "    \n",
    "    anchor_sizes = ((16,), (32,), (64,), (128,), (256,),)\n",
    "    aspect_ratios = ((0.5, 1.0, 2.0),) * len(anchor_sizes)\n",
    "    \n",
    "    anchor_generator = AnchorGenerator(sizes=anchor_sizes, aspect_ratios=aspect_ratios)\n",
    "\n",
    "    model = FasterRCNN(backbone,\n",
    "                       num_classes=num_classes,\n",
    "                       rpn_anchor_generator=anchor_generator,\n",
    "                       box_fg_iou_thresh=0.5,\n",
    "                       box_bg_iou_thresh=0.5,\n",
    "                       image_mean = [0.0, 0.0, 0.0], # already normalized by fastai\n",
    "                       image_std = [1.0, 1.0, 1.0],\n",
    "                       #min_size = 1,\n",
    "                       #box_score_thresh=0.6,\n",
    "                       **kwargs\n",
    "                      )\n",
    "    \n",
    "\n",
    "    if pretrained:\n",
    "        try:\n",
    "            pretrained_dict = load_state_dict_from_url(_model_urls['fasterrcnn_'+arch_str+'_fpn_coco'], progress=True)\n",
    "            model_dict = model.state_dict()\n",
    "            \n",
    "            pretrained_dict = {k: v for k, v in pretrained_dict.items() if\n",
    "                       (k in model_dict) and (model_dict[k].shape == pretrained_dict[k].shape)}\n",
    "                     \n",
    "            model_dict.update(pretrained_dict) \n",
    "            model.load_state_dict(model_dict)\n",
    "            #overwrite_eps(model, 0.0)\n",
    "            for module in model.modules():\n",
    "                if isinstance(module, FrozenBatchNorm2d):\n",
    "                    module.eps = 0.0\n",
    "            \n",
    "        except Exception as e: \n",
    "            #print(e)\n",
    "            print(\"No pretrained coco model found for fasterrcnn_\"+arch_str)\n",
    "            print(\"This does not affect the backbone.\")\n",
    "            \n",
    "    return model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "@delegates(FasterRCNN)\n",
    "def get_fasterrcnn_model_swin(arch_str, num_classes, pretrained=False, pretrained_backbone=True, **kwargs):\n",
    "    \"\"\"Creates FasterRCNN model with swin transformer backbone\"\"\"\n",
    "    anchor_sizes = ((32,), (64,), (128,), (256,),)\n",
    "    aspect_ratios = ((0.5, 1.0, 2.0),) * len(anchor_sizes)\n",
    "    anchor_generator = AnchorGenerator(sizes=anchor_sizes, aspect_ratios=aspect_ratios)\n",
    "    #roi_pooler = torchvision.ops.MultiScaleRoIAlign(featmap_names=['0','1','2','3'],\n",
    "    #                                                output_size=7,\n",
    "    #                                                sampling_ratio=2)\n",
    "    \n",
    "    img_size = 224 if arch_str in \"swin_tiny swin_small\".split() else 384\n",
    "    window_size = 7 if arch_str in \"swin_tiny swin_small\".split() else 12\n",
    "    depths = [2, 2, 6, 2] if arch_str==\"swin_tiny\" else [2, 2, 18, 2]\n",
    "    \n",
    "    scale_factors = {\"swin_tiny\":1.0, \"swin_small\":1.5, \"swin_base\":2.0, \"swin_large\":2.0}\n",
    "    sf = scale_factors[arch_str]\n",
    "    embed_dim = int(96*sf)\n",
    "    fpn_cin = [int(96*sf*2**i) for i in range(4)]\n",
    "    #fpn_cin = [int(i*sf) for i in [96, 192, 384, 768]]\n",
    "    \n",
    "    backbone = SwinTransformerFPN(img_size=img_size, window_size=window_size, embed_dim=embed_dim, \n",
    "                                  depths=depths, fpn_cin=fpn_cin, fpn_cout=256)\n",
    "    \n",
    "    if pretrained_backbone:\n",
    "        sd = load_state_dict_from_url(_model_urls[f'{arch_str}_{img_size}'], \n",
    "                                      progress=True, map_location=default_device())['model']\n",
    "        sd_model = backbone.state_dict()\n",
    "        sd = {k: v for k, v in sd.items() if k in sd_model.keys()}\n",
    "        sd_model.update(sd)\n",
    "        backbone.load_state_dict(sd_model)\n",
    "\n",
    "    model = FasterRCNN(backbone,\n",
    "                       num_classes=num_classes,\n",
    "                       rpn_anchor_generator=anchor_generator,\n",
    "                       #box_roi_pool=roi_pooler,\n",
    "                       box_fg_iou_thresh=0.5,\n",
    "                       box_bg_iou_thresh=0.5,\n",
    "                       image_mean = [0.0, 0.0, 0.0], # already normalized by fastai\n",
    "                       image_std = [1.0, 1.0, 1.0],\n",
    "                       #min_size=IMG_SIZE,\n",
    "                       #max_size=IMG_SIZE,\n",
    "                       **kwargs\n",
    "                      )\n",
    "                       \n",
    "    return model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "#hide\n",
    "\n",
    "class SwinTransformerFPN(nn.Module):\n",
    "    def __init__(self, img_size=224, window_size=7, embed_dim=96, \n",
    "                 depths=[2, 2, 6, 2], fpn_cin=[96, 192, 384, 768], fpn_cout=256):\n",
    "        \"\"\"SwinTransformer backbone with feature pyramid network.\"\"\"\n",
    "        super().__init__()\n",
    "        self.body = SwinTransformer(pretrain_img_size=img_size, patch_size=4, in_chans=3, \n",
    "                                    embed_dim=embed_dim, depths=depths, num_heads=[3, 6, 12, 24],\n",
    "                                    window_size=window_size, mlp_ratio=4.0, qkv_bias=True, qk_scale=None, drop_rate=0.0, \n",
    "                                    attn_drop_rate=0.0, drop_path_rate=0.2, norm_layer=torch.nn.modules.normalization.LayerNorm,\n",
    "                                    ape=False,patch_norm=True, out_indices=(0, 1, 2, 3), frozen_stages=-1, use_checkpoint=False)\n",
    "        \n",
    "        self.fpn = FeaturePyramidNetwork(in_channels_list=fpn_cin,  out_channels=fpn_cout)\n",
    "        self.out_channels = fpn_cout\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.body(x)\n",
    "        features = {f\"{i}\":v for i,v in enumerate(x)}\n",
    "        return self.fpn(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "#hide\n",
    "fasterrcnn_resnet18 = partial(get_fasterrcnn_model, arch_str=\"resnet18\")\n",
    "fasterrcnn_resnet34 = partial(get_fasterrcnn_model, arch_str=\"resnet34\")\n",
    "fasterrcnn_resnet50 = partial(get_fasterrcnn_model, arch_str=\"resnet50\")\n",
    "fasterrcnn_resnet101 = partial(get_fasterrcnn_model, arch_str=\"resnet101\")\n",
    "fasterrcnn_resnet152 = partial(get_fasterrcnn_model, arch_str=\"resnet152\")\n",
    "fasterrcnn_swinT = partial(get_fasterrcnn_model_swin, arch_str=\"swin_tiny\")\n",
    "fasterrcnn_swinS = partial(get_fasterrcnn_model_swin, arch_str=\"swin_small\")\n",
    "fasterrcnn_swinB = partial(get_fasterrcnn_model_swin, arch_str=\"swin_base\")\n",
    "fasterrcnn_swinL = partial(get_fasterrcnn_model_swin, arch_str=\"swin_large\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom FasterRCNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a model, which you can pass to a `ObjDetLearner` simply create a `partial` with the functions `get_fasterrcnn_model` (resnet backbone) or `get_fasterrcnn_model_swin` (swin transformer backbone)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "custom_fasterrcnn = partial(get_fasterrcnn_model, arch_str=\"resnet18\", \n",
    "                            pretrained=True, pretrained_backbone=True, \n",
    "                            min_size=600, max_size=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When building the `Learner`, the number of classes are getting passed to this partial function and the model is ready for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No pretrained coco model found for fasterrcnn_resnet18\n",
      "This does not affect the backbone.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "FasterRCNN(\n",
       "  (transform): GeneralizedRCNNTransform(\n",
       "      Normalize(mean=[0.0, 0.0, 0.0], std=[1.0, 1.0, 1.0])\n",
       "      Resize(min_size=(600,), max_size=600, mode='bilinear')\n",
       "  )\n",
       "  (backbone): BackboneWithFPN(\n",
       "    (body): IntermediateLayerGetter(\n",
       "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (bn1): FrozenBatchNorm2d(64)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (layer1): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64)\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64)\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(128)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128)\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(256)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256)\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(512)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (fpn): FeaturePyramidNetwork(\n",
       "      (inner_blocks): ModuleList(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (layer_blocks): ModuleList(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (extra_blocks): LastLevelMaxPool()\n",
       "    )\n",
       "  )\n",
       "  (rpn): RegionProposalNetwork(\n",
       "    (anchor_generator): AnchorGenerator()\n",
       "    (head): RPNHead(\n",
       "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (cls_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bbox_pred): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (roi_heads): RoIHeads(\n",
       "    (box_roi_pool): MultiScaleRoIAlign()\n",
       "    (box_head): TwoMLPHead(\n",
       "      (fc6): Linear(in_features=12544, out_features=1024, bias=True)\n",
       "      (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    )\n",
       "    (box_predictor): FastRCNNPredictor(\n",
       "      (cls_score): Linear(in_features=1024, out_features=5, bias=True)\n",
       "      (bbox_pred): Linear(in_features=1024, out_features=20, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_fasterrcnn(num_classes=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prebuilt models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some prebuilt model partials, which you can use instantly:\n",
    "\n",
    "Resnet Backbone:\n",
    "* `fasterrcnn_resnet18`\n",
    "* `fasterrcnn_resnet34`\n",
    "* `fasterrcnn_resnet50`\n",
    "* `fasterrcnn_resnet101`\n",
    "* `fasterrcnn_resnet152`\n",
    "\n",
    "\n",
    "Swin Transformer Backbone:\n",
    "* `fasterrcnn_swinT` (tiny)\n",
    "* `fasterrcnn_swinS` (small)\n",
    "* `fasterrcnn_swinB` (base)\n",
    "* `fasterrcnn_swinL` (large)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
