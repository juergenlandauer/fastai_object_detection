{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp learners"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learners\n",
    "\n",
    "> API details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from nbdev.showdoc import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "from fastprogress.fastprogress import progress_bar\n",
    "from fastai.vision.all import *\n",
    "from fastai_object_detection.callbacks import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "class ObjDetLearner(Learner): pass\n",
    "class InstSegLearner(Learner): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def no_split(m):\n",
    "    \"No split of params for models\"\n",
    "    return L(m).map(params)\n",
    "\n",
    "def rcnn_split(m):\n",
    "    \"Default split of params for fasterrcnn/maskrcnn models\"\n",
    "    body_params, head_params = L(params(m.backbone)), L()\n",
    "    for p in [m.rpn, m.roi_heads]:\n",
    "        head_params += params(p)\n",
    "    return L(body_params, head_params)\n",
    "\n",
    "def effdet_split(m):\n",
    "    \"Default split of params for efficientdet models\"\n",
    "    body_params, head_params = L(),L() \n",
    "    for p in [m.model.backbone_net, m.model.bifpn, m.model.anchors]:\n",
    "        body_params += params(p)\n",
    "    for p in [m.model.classifier, m.model.regressor]:\n",
    "        head_params += params(p)\n",
    "    return L(body_params, head_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "class fasterrcnn_learner(ObjDetLearner):\n",
    "    \"\"\" fastai-style learner to train fasterrcnn models \"\"\"\n",
    "    def __init__(self, dls, model, pretrained=True, pretrained_backbone=True, num_classes=None,\n",
    "                 # learner args\n",
    "                 loss_func=noop, opt_func=Adam, lr=defaults.lr, splitter=None, cbs=None, metrics=None, path=None,\n",
    "                 model_dir='models', wd=None, wd_bn_bias=False, train_bn=True, moms=(0.95,0.85,0.95),\n",
    "                 # other model args\n",
    "                 **kwargs):\n",
    "                \n",
    "        num_classes = len(dls.vocab) if num_classes is None else num_classes\n",
    "        cbs = [ObjDetAdapter()] if cbs is None else L(ObjDetAdapter())+L(cbs)\n",
    "        #if cbs is None: cbs = [ObjDetAdapter()]\n",
    "        #else: cbs = L(ObjDetAdapter())+L(cbs)\n",
    "        model = model(num_classes=num_classes, pretrained=pretrained, pretrained_backbone=pretrained_backbone, **kwargs)\n",
    "        splitter = rcnn_split if splitter is None else splitter\n",
    "            \n",
    "        super().__init__(dls=dls, model=model, loss_func=loss_func, opt_func=opt_func, lr=lr, splitter=splitter, cbs=cbs,\n",
    "                   metrics=metrics, path=path, model_dir=model_dir, wd=wd, wd_bn_bias=wd_bn_bias, train_bn=train_bn,\n",
    "                   moms=moms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "class maskrcnn_learner(InstSegLearner):\n",
    "    \"\"\" fastai-style learner to train maskrcnn models \"\"\"\n",
    "    def __init__(self, dls, model, pretrained=True, pretrained_backbone=True, num_classes=None,\n",
    "                 # learner args\n",
    "                 loss_func=noop, opt_func=Adam, lr=defaults.lr, splitter=None, cbs=None, metrics=None, path=None,\n",
    "                 model_dir='models', wd=None, wd_bn_bias=False, train_bn=True, moms=(0.95,0.85,0.95),\n",
    "                 # other model args\n",
    "                 **kwargs):    \n",
    "        \n",
    "        num_classes = len(dls.vocab) if num_classes is None else num_classes     \n",
    "        cbs = [ObjDetAdapter()] if cbs is None else L(ObjDetAdapter())+L(cbs)\n",
    "        model = model(num_classes=num_classes, pretrained=pretrained, pretrained_backbone=pretrained_backbone, **kwargs)\n",
    "        splitter = rcnn_split if splitter is None else splitter\n",
    "        \n",
    "        super().__init__(dls=dls, model=model, loss_func=loss_func, opt_func=opt_func, lr=lr, splitter=splitter, cbs=cbs,\n",
    "                   metrics=metrics, path=path, model_dir=model_dir, wd=wd, wd_bn_bias=wd_bn_bias, train_bn=train_bn,\n",
    "                   moms=moms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "class efficientdet_learner(ObjDetLearner):\n",
    "    \"\"\" fastai-style learner to train efficientdet models \"\"\"\n",
    "    def __init__(self, dls, model, pretrained=True, pretrained_backbone=True, num_classes=None,\n",
    "                 # learner args\n",
    "                 loss_func=noop, opt_func=Adam, lr=defaults.lr, splitter=None, cbs=None, metrics=None, path=None,\n",
    "                 model_dir='models', wd=None, wd_bn_bias=False, train_bn=True, moms=(0.95,0.85,0.95),\n",
    "                 # other model args\n",
    "                 **kwargs):\n",
    "                \n",
    "        if num_classes is None: num_classes = len(dls.vocab) - 1 # without #na#, no background\n",
    "        \n",
    "        cbs = [ObjDetAdapter()] if cbs is None else L(ObjDetAdapter())+L(cbs)\n",
    "            \n",
    "        model = model(num_classes=num_classes, pretrained=pretrained, pretrained_backbone=pretrained_backbone, **kwargs)\n",
    "        \n",
    "        if splitter is None: splitter = effdet_split\n",
    "            \n",
    "        super().__init__(dls=dls, model=model, loss_func=loss_func, opt_func=opt_func, lr=lr, splitter=splitter, cbs=cbs,\n",
    "                   metrics=metrics, path=path, model_dir=model_dir, wd=wd, wd_bn_bias=wd_bn_bias, train_bn=train_bn,\n",
    "                   moms=moms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "@patch\n",
    "def get_preds(x:ObjDetLearner, items=None, item_tfms=None, batch_tfms=None, \n",
    "              box_score_thresh=0.05, max_n=None, progress=True):\n",
    "    \n",
    "    if items is not None:\n",
    "        #if item_tfms is None: item_tfms = [Resize(800, method=\"pad\", pad_mode=\"zeros\")]\n",
    "        dblock = DataBlock(\n",
    "            blocks=(ImageBlock(cls=PILImage)),\n",
    "            item_tfms=item_tfms,\n",
    "            batch_tfms=batch_tfms)\n",
    "        test_dl = dblock.dataloaders(items).test_dl(items, bs=x.dls.bs)\n",
    "    else:\n",
    "        test_dl = x.dls.valid.new(shuffle=True)\n",
    "\n",
    "    inputs,preds = [],[]\n",
    "    with torch.no_grad():\n",
    "        for i,batch in enumerate(progress_bar(test_dl, display=progress)):\n",
    "            x.model.eval()\n",
    "            preds.append(x.model(batch[0]))\n",
    "            inputs.append(batch[0])\n",
    "            x.model.train()\n",
    "            if max_n is not None:\n",
    "                if len(inputs)*test_dl.bs>=max_n:\n",
    "                    break\n",
    "    # preds: num_batches x bs x dict[\"boxes\", \"labels\", \"scores\"]\n",
    "    # flatten:\n",
    "    preds = [i for p in preds for i in p]\n",
    "    inputs = [i for inp in inputs for i in inp]\n",
    "\n",
    "    preds = [torch.cat([p[\"boxes\"],p[\"labels\"].unsqueeze(1),p[\"scores\"].unsqueeze(1)], dim=1).cpu() \n",
    "             for p in preds]\n",
    "\n",
    "    # only preds with score > box_score_thresh\n",
    "    preds = [p[p[:,5]>box_score_thresh] for p in preds]\n",
    "\n",
    "    # only preds with bbox area > 0\n",
    "    filt = [((p[:,3]-p[:,1])*(p[:,2]-p[:,0]))>0 for p in preds]\n",
    "    preds = [p[filt[i]] for i,p in enumerate(preds)]\n",
    "\n",
    "    # denormalize inputs\n",
    "    inputs = [x.dls.valid.decode([i])[0][0] for i in inputs]\n",
    "\n",
    "    boxes = [p[:,:4] for p in preds]\n",
    "    labels = [p[:,4] for p in preds]\n",
    "    scores = [p[:,5] for p in preds]\n",
    "\n",
    "    return inputs, boxes, labels, scores \n",
    "\n",
    "\n",
    "@patch\n",
    "def show_results(x:ObjDetLearner, items=None, item_tfms=None, batch_tfms=None, \n",
    "                 box_score_thresh=0.50, max_n=None, progress=False):\n",
    "    \n",
    "    inputs, boxes, labels, scores = x.get_preds(items=items, item_tfms=item_tfms, batch_tfms=batch_tfms, \n",
    "                                                   box_score_thresh=box_score_thresh, max_n=max_n, progress=progress)\n",
    "    for idx in range(len(inputs)):\n",
    "        if max_n is not None:\n",
    "            if idx >= max_n: break\n",
    "        fig, ax = plt.subplots(figsize=(8,8))\n",
    "        TensorImage(inputs[idx]).show(ax=ax)\n",
    "        LabeledBBox(TensorBBox(boxes[idx]), [x.dls.vocab[int(l.item())] \n",
    "                                                for l in labels[idx]]).show(ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "@patch\n",
    "def get_preds(x:InstSegLearner, items, item_tfms=None, batch_tfms=None, box_score_thresh=0.05, bin_mask_thresh=None):\n",
    "    if item_tfms is None: item_tfms = [Resize(800, method=\"pad\", pad_mode=\"zeros\")]\n",
    "    dblock = DataBlock(\n",
    "        blocks=(ImageBlock(cls=PILImage)),\n",
    "        item_tfms=item_tfms,\n",
    "        batch_tfms=batch_tfms)\n",
    "    test_dl = dblock.dataloaders(items).test_dl(items, bs=x.dls.bs)\n",
    "    inputs,preds = [],[]\n",
    "    with torch.no_grad():\n",
    "        for i,batch in enumerate(progress_bar(test_dl)):\n",
    "            x.model.eval()\n",
    "            preds.append(x.model(*batch))\n",
    "            inputs.append(*batch)\n",
    "            x.model.train()\n",
    "    # preds: num_batches x bs x dict[\"boxes\", \"labels\", ...]\n",
    "    # flatten:\n",
    "    preds = [i for p in preds for i in p]\n",
    "    inputs = [i.cpu() for inp in inputs for i in inp]\n",
    "\n",
    "    # maskrcnn pred shapes\n",
    "    # masks: [N, 1, H, W]\n",
    "    # boxes: [N, 4]\n",
    "    # labels: [N]\n",
    "    # scores: [N]\n",
    "\n",
    "    # filter out predictions under threshold\n",
    "    filt = [p[\"scores\"]>box_score_thresh for p in preds]\n",
    "\n",
    "    masks = [p[\"masks\"][filt[i]].cpu() for i,p in enumerate(preds)]\n",
    "    boxes = [p[\"boxes\"][filt[i]].cpu() for i,p in enumerate(preds)]\n",
    "    labels = [p[\"labels\"][filt[i]].cpu() for i,p in enumerate(preds)]\n",
    "    scores = [p[\"scores\"][filt[i]].cpu() for i,p in enumerate(preds)]\n",
    "\n",
    "    # denormalize inputs\n",
    "    inputs = [x.dls.valid.decode([i])[0][0] for i in inputs]\n",
    "\n",
    "    #print(len(masks))\n",
    "    # by default returns masks in [N, 1, H, W] with activations\n",
    "    # if you want binary masks in [N, H, W] set bin_mask_thresh \n",
    "    if bin_mask_thresh is not None:\n",
    "        for i,m in enumerate(masks):\n",
    "            masks[i] = torch.where(m > bin_mask_thresh, 1, 0).squeeze(1)\n",
    "\n",
    "    return inputs, masks, boxes, labels, scores\n",
    "\n",
    "\n",
    "@patch\n",
    "def show_results(x:InstSegLearner, items, max_n=9, box_score_thresh=0.6, bin_mask_thresh=0.5, **kwargs):\n",
    "    inputs, masks, bboxes, labels, scores  = x.get_preds(items=items, box_score_thresh=box_score_thresh)\n",
    "\n",
    "    for i,m in enumerate(masks):\n",
    "        background = torch.ones([1,1,m.shape[-2],m.shape[-1]]) * bin_mask_thresh \n",
    "        m = torch.cat([background, m])\n",
    "        masks[i] = torch.argmax(m, dim=0).squeeze(0)\n",
    "\n",
    "    #idx = 10\n",
    "    for idx in range(len(inputs)):\n",
    "        if max_n is not None:\n",
    "            if idx >= max_n: break\n",
    "        fig, ax = plt.subplots(figsize=(8,8))\n",
    "        TensorImage(inputs[idx]).show(ax=ax),\n",
    "        TensorMask(masks[idx]).show(ax),\n",
    "        LabeledBBox(TensorBBox(bboxes[idx]), [x.dls.vocab[int(l.item())] \n",
    "                                              for l in labels[idx]]).show(ax)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
