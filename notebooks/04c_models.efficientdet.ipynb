{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp models.efficientdet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EfficientDet\n",
    "\n",
    "> API - details..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from nbdev.showdoc import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import torch\n",
    "from torch.nn import Module\n",
    "from torchvision.ops.boxes import batched_nms\n",
    "from torchvision.models.utils import load_state_dict_from_url\n",
    "from functools import partial\n",
    "from fastai.vision.all import delegates\n",
    "from fastai_object_detection.external.efficientdet_source import FocalLoss, BBoxTransform, ClipBoxes, EfficientDetBackbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "\n",
    "class EffDetModelWrapper(Module):\n",
    "    def __init__(self, num_classes, compound_coef=0, pretrained=True, pretrained_backbone=True, \n",
    "                 nms_score_thresh=0.05, nms_iou_thresh=0.50, ratios='[(1.0,1.0),(1.4,0.7),(0.7,1.4)]', \n",
    "                 scales='[2**0, 2**(1.0/3.0), 2**(2.0/3.0)]', focal_loss_alpha=0.25, focal_loss_gamma=2.0, \n",
    "                 **kwargs):\n",
    "        \"\"\"Wrapper for EfficientDet model combined with loss function\"\"\"\n",
    "        super().__init__()\n",
    "        self.criterion = FocalLoss(alpha=focal_loss_alpha, gamma=focal_loss_gamma)\n",
    "        self.model = EfficientDetBackbone(num_classes=num_classes, compound_coef=compound_coef, ratios=eval(ratios), scales=eval(scales))\n",
    "        self.model.train()\n",
    "        self.training = True\n",
    "        self.nms_score_thresh = nms_score_thresh\n",
    "        self.nms_iou_thresh = nms_iou_thresh\n",
    "        self.regressBoxes = BBoxTransform()\n",
    "        self.clipBoxes = ClipBoxes()\n",
    "        self.device = device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    def forward(self, *x):\n",
    "        imgs, targets = x if len(x)==2 else (x[0], None)\n",
    "        imgs, targets = self.preprocess(imgs, targets)\n",
    "        features, regression, classification, anchors = self.model(imgs)\n",
    "\n",
    "        if targets is not None:\n",
    "            cls_loss, reg_loss = self.criterion(classification, regression, anchors, targets)\n",
    "            return {\"cls_loss\":cls_loss, \"reg_loss\":reg_loss}\n",
    "        else:\n",
    "            preds = self.postprocess(imgs, anchors, regression, classification)\n",
    "            return preds\n",
    "\n",
    "    def train(self):\n",
    "        self.model.train()\n",
    "        self.training = True\n",
    "\n",
    "    def eval(self):\n",
    "        self.model.eval()\n",
    "        self.training = False\n",
    "\n",
    "    def preprocess(self, imgs, targets=None):\n",
    "        if targets is None:\n",
    "            annotations = None\n",
    "        else: \n",
    "            bboxes = [d[\"boxes\"] for d in targets]\n",
    "            labels = [d[\"labels\"] - 1 for d in targets] # 0 is background in dataloader, but first class in model\n",
    "            annotations = [torch.cat([b,l.unsqueeze(1)], dim=1) for b,l in zip(bboxes, labels)]\n",
    "            # padding with -1\n",
    "            max_len = max([len(b) for b in annotations])\n",
    "            annotations = torch.stack([torch.cat([b, b.new_ones([max_len-len(b),5])*-1], dim=0) for b in annotations])\n",
    "        return imgs, annotations\n",
    "\n",
    "    def postprocess(self, x, anchors, regression, classification):\n",
    "        # modified from https://github.com/zylo117/Yet-Another-EfficientDet-Pytorch/blob/master/utils/utils.py\n",
    "        transformed_anchors = self.regressBoxes(anchors, regression)\n",
    "        transformed_anchors = self.clipBoxes(transformed_anchors, x)\n",
    "        scores = torch.max(classification, dim=2, keepdim=True)[0]\n",
    "        scores_over_thresh = (scores > self.nms_score_thresh)[:, :, 0]\n",
    "        out = []\n",
    "        for i in range(x.shape[0]):\n",
    "            if scores_over_thresh[i].sum() == 0:\n",
    "                out.append({\n",
    "                    'boxes': torch.tensor(()),\n",
    "                    'labels': torch.tensor(()),\n",
    "                    'scores': torch.tensor(()),\n",
    "                })\n",
    "                continue\n",
    "\n",
    "            classification_per = classification[i, scores_over_thresh[i, :], ...].permute(1, 0)\n",
    "            transformed_anchors_per = transformed_anchors[i, scores_over_thresh[i, :], ...]\n",
    "            scores_per = scores[i, scores_over_thresh[i, :], ...]\n",
    "            scores_, classes_ = classification_per.max(dim=0)\n",
    "            anchors_nms_idx = batched_nms(transformed_anchors_per, scores_per[:, 0], classes_, iou_threshold=self.nms_iou_thresh)\n",
    "\n",
    "            if anchors_nms_idx.shape[0] != 0:\n",
    "                classes_ = classes_[anchors_nms_idx] + 1 # 0 is background and gets removed in metric, but is first class in model\n",
    "                scores_ = scores_[anchors_nms_idx]\n",
    "                boxes_ = transformed_anchors_per[anchors_nms_idx, :]\n",
    "\n",
    "                out.append({\n",
    "                    'boxes': boxes_.cpu(),\n",
    "                    'labels': classes_.cpu(),\n",
    "                    'scores': scores_.cpu(),\n",
    "                })\n",
    "            else:\n",
    "                out.append({\n",
    "                    'boxes': torch.tensor(()),\n",
    "                    'labels': torch.tensor(()),\n",
    "                    'scores': torch.tensor(()),\n",
    "                })\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "# hide      \n",
    "      \n",
    "_effdet_model_urls = {\n",
    "    \"efficientdet-d0\": \"https://github.com/zylo117/Yet-Another-Efficient-Pytorch/releases/download/1.0/efficientdet-d0.pth\",\n",
    "    \"efficientdet-d1\": \"https://github.com/zylo117/Yet-Another-Efficient-Pytorch/releases/download/1.0/efficientdet-d1.pth\",\n",
    "    \"efficientdet-d2\": \"https://github.com/zylo117/Yet-Another-Efficient-Pytorch/releases/download/1.0/efficientdet-d2.pth\",\n",
    "    \"efficientdet-d3\": \"https://github.com/zylo117/Yet-Another-Efficient-Pytorch/releases/download/1.0/efficientdet-d3.pth\",\n",
    "    \"efficientdet-d4\": \"https://github.com/zylo117/Yet-Another-Efficient-Pytorch/releases/download/1.0/efficientdet-d4.pth\",\n",
    "    \"efficientdet-d5\": \"https://github.com/zylo117/Yet-Another-Efficient-Pytorch/releases/download/1.0/efficientdet-d5.pth\",\n",
    "    \"efficientdet-d6\": \"https://github.com/zylo117/Yet-Another-Efficient-Pytorch/releases/download/1.0/efficientdet-d6.pth\",\n",
    "    \"efficientdet-d7\": \"https://github.com/zylo117/Yet-Another-Efficient-Pytorch/releases/download/1.0/efficientdet-d7.pth\"\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "@delegates(EffDetModelWrapper)\n",
    "def get_efficientdet_model(num_classes, compound_coef=0, pretrained_backbone=True, pretrained=True, \n",
    "                           nms_score_thresh=0.05, nms_iou_thresh=0.50 , \n",
    "                           focal_loss_alpha=0.25, focal_loss_gamma=2.0, **kwargs):\n",
    "    \"\"\"get_efficientdet_model\"\"\"\n",
    "\n",
    "    arch_str = f\"efficientdet-d{compound_coef}\"\n",
    "    model = EffDetModelWrapper(num_classes=num_classes, compound_coef=compound_coef, nms_score_thresh=nms_score_thresh, nms_iou_thresh=nms_iou_thresh, focal_loss_alpha=focal_loss_alpha, focal_loss_gamma=focal_loss_gamma, **kwargs)\n",
    "\n",
    "    if pretrained or pretrained_backbone:\n",
    "        try:\n",
    "            pretrained_dict = load_state_dict_from_url(_effdet_model_urls[arch_str], progress=True)\n",
    "            model_dict = model.model.state_dict()\n",
    "            pretrained_dict = {k: v for k, v in pretrained_dict.items() if\n",
    "                        (k in model_dict) and (model_dict[k].shape == pretrained_dict[k].shape)}\n",
    "            model_dict.update(pretrained_dict) \n",
    "            model.model.load_state_dict(model_dict)\n",
    "        except:\n",
    "            print(\"Error loading pretrained model\")\n",
    "\n",
    "    return model \n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "# hide\n",
    "\n",
    "efficientdet_d0 = partial(get_efficientdet_model, compound_coef=0)  \n",
    "efficientdet_d1 = partial(get_efficientdet_model, compound_coef=1)\n",
    "efficientdet_d2 = partial(get_efficientdet_model, compound_coef=2)  \n",
    "efficientdet_d3 = partial(get_efficientdet_model, compound_coef=3)\n",
    "efficientdet_d4 = partial(get_efficientdet_model, compound_coef=4)  \n",
    "efficientdet_d5 = partial(get_efficientdet_model, compound_coef=5)\n",
    "efficientdet_d6 = partial(get_efficientdet_model, compound_coef=6)  \n",
    "efficientdet_d7 = partial(get_efficientdet_model, compound_coef=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
